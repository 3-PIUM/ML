{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gRBHecsc5I1"
      },
      "source": [
        "- https://github.com/PSY222/Colorinsight  git clone\n",
        "- gitì— ìˆëŠ” pthë¥¼ ë‹¤ìš´ë°›ìŒ.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dTETzBIIJCx",
        "outputId": "fc67e5c4-e414-4270-b8e9-c7546168b37d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Colorinsight'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 86 (delta 6), reused 5 (delta 0), pack-reused 57 (from 1)\u001b[K\n",
            "Receiving objects: 100% (86/86), 109.40 MiB | 21.05 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PSY222/Colorinsight.git ##ìˆ˜ì •"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV4yzsr0dLei"
      },
      "source": [
        "- pthë¥¼ ptë¡œ ë§Œë“¤ì–´ì„œ ë§¤ë²ˆ ëª¨ë¸ ë¡œë“œ í•˜ì§€ ì•Šê²Œ í•¨.\n",
        "- ptê°€ ìˆìœ¼ë©´ ì‹¤í–‰ã„´ã„´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7OwmHy-SciXG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 4)\n",
        "\n",
        "# state_dict ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model.load_state_dict(torch.load('best_model_resnet_ALL.pth', map_location='cpu'))\n",
        "\n",
        "# ëª¨ë¸ ì „ì²´ ì €ì¥\n",
        "torch.save(model, 'best_model_resnet_ALL.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUqFc_K1ckwi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAWxG95cdRRR"
      },
      "source": [
        "- best_model_resnet_ALL.ptë¥¼ ì´ìš©í•´ì„œ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨.\n",
        "- pt ë‹¤ìš´ë°›ì•„ì„œ ì•„ë˜ ì½”ë“œë§Œ ì‹¤í–‰."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.7.0)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Downloading torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ------------------------ --------------- 1.0/1.7 MB 8.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.7/1.7 MB 5.8 MB/s eta 0:00:00\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.22.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ì‚¬ì§„ 1ê°œë§Œ ì“¸ ë•Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmdgdtqSZIHY",
        "outputId": "face32bf-897e-4946-886c-823818cee1f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decided color: ê²¨ìš¸ì¿¨ (3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "def get_season(img_path):\n",
        "    # ëª¨ë¸ ì „ì²´ ë¡œë“œ (êµ¬ì¡° + ê°€ì¤‘ì¹˜)\n",
        "    model = torch.load('best_model_resnet_ALL.pt', map_location='cpu', weights_only=False)\n",
        "    model.eval()\n",
        "\n",
        "    # ì „ì²˜ë¦¬ ì •ì˜\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)\n",
        "\n",
        "    # ì˜ˆì¸¡\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "\n",
        "    pred_index = output.argmax().item()\n",
        "    classes = ['ë´„ì›œ', 'ì—¬ë¦„ì¿¨', 'ê°€ì„ì›œ', 'ê²¨ìš¸ì¿¨']\n",
        "    print(f\"Decided color: {classes[pred_index]} ({pred_index})\")\n",
        "    return pred_index\n",
        "\n",
        "# ì˜ˆì‹œ ì‹¤í–‰\n",
        "get_season(\"C:/Users/user/Desktop/test5.jpg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ì‚¬ì§„ ì—¬ëŸ¬ ê°œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rkdFjq0-aIue"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¸ Hard Voting ë°©ì‹:\n",
            "âœ… Hard Voting ê²°ê³¼: ì—¬ë¦„ì¿¨ (index 1)\n",
            "\n",
            "ğŸ”¸ Soft Voting ë°©ì‹:\n",
            "âœ… Soft Voting ê²°ê³¼: ì—¬ë¦„ì¿¨ (index 1)\n",
            "Confidence scores: [0.04919267 0.5238123  0.1427133  0.28428173]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# í´ë˜ìŠ¤ ì´ë¦„\n",
        "CLASSES = ['ë´„ì›œ', 'ì—¬ë¦„ì¿¨', 'ê°€ì„ì›œ', 'ê²¨ìš¸ì¿¨']\n",
        "\n",
        "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "def load_model(model_path='best_model_resnet_ALL.pt'):\n",
        "    model = torch.load(model_path, map_location='cpu', weights_only=False)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ í•¨ìˆ˜\n",
        "def predict_single(model, img_path):\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "    return output\n",
        "\n",
        "# ë°©ì‹ 1: Hard Voting (ê°€ì¥ ë§ì´ ë‚˜ì˜¨ í´ë˜ìŠ¤)\n",
        "def get_season_hard_vote(img_paths):\n",
        "    model = load_model()\n",
        "    results = []\n",
        "    for path in img_paths:\n",
        "        output = predict_single(model, path)\n",
        "        pred = output.argmax().item()\n",
        "        results.append(pred)\n",
        "\n",
        "    most_common = Counter(results).most_common(1)[0][0]\n",
        "    print(f\"âœ… Hard Voting ê²°ê³¼: {CLASSES[most_common]} (index {most_common})\")\n",
        "    return most_common\n",
        "\n",
        "# ë°©ì‹ 2: Soft Voting (í™•ë¥  í‰ê· )\n",
        "def get_season_soft_vote(img_paths):\n",
        "    model = load_model()\n",
        "    all_probs = []\n",
        "    for path in img_paths:\n",
        "        output = predict_single(model, path)\n",
        "        probs = F.softmax(output, dim=1).numpy()\n",
        "        all_probs.append(probs)\n",
        "\n",
        "    mean_prob = np.mean(np.vstack(all_probs), axis=0)\n",
        "    pred_index = np.argmax(mean_prob)\n",
        "    print(f\"âœ… Soft Voting ê²°ê³¼: {CLASSES[pred_index]} (index {pred_index})\")\n",
        "    print(f\"Confidence scores: {mean_prob}\")\n",
        "    return pred_index\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ\n",
        "if __name__ == \"__main__\":\n",
        "    img_list = [\n",
        "        \"C:/Users/user/Desktop/test.jpg\",\n",
        "        \"C:/Users/user/Desktop/test2.jpg\",\n",
        "        \"C:/Users/user/Desktop/test3.jpg\",\n",
        "        \"C:/Users/user/Desktop/test4.jpg\",\n",
        "        \"C:/Users/user/Desktop/test5.jpg\"\n",
        "    ]\n",
        "    \n",
        "    print(\"\\nğŸ”¸ Hard Voting ë°©ì‹:\")\n",
        "    get_season_hard_vote(img_list)\n",
        "\n",
        "    print(\"\\nğŸ”¸ Soft Voting ë°©ì‹:\")\n",
        "    get_season_soft_vote(img_list)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
